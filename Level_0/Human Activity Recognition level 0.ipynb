{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ashishpal2702/HumanActivityrecognition/blob/main/Logistic_Regression_and_Classification_POC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HMCUKoLjOLyO"
   },
   "source": [
    "## Human Activity Recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach to Problem Statement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s go ahead and open the Human activity recognition level 0 notebook. In this notebook we will be building the level 0 architecture of MLOps, and our major focus would be on the model registry part. The basic analysis and data visualisation steps are skipped in the interest of time. The major take away for this lesson is to learn:\n",
    "\n",
    "* How to manually save the results of the modelling experiments and the dataset used for modelling?\n",
    "* How to manually save the models under the model registry? and,\n",
    "* How to use the saved models at a later stage?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries:\n",
    "Let’s start by importing the relevant libraries for the model-building process. \n",
    "1. Import libraries like os, pandas, and numpy for data handling and feature engineering processes.\n",
    "2. Import necessary Scikit-learn libraries for the model-building and evaluation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "hQoLjWtEOLyR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "RVdIsc3nOLyT"
   },
   "source": [
    "## 1. Data Import\n",
    "\n",
    "Now, let’s import the dataset present in the variable file path. Please change the file paths accordingly to the location of the data in your system. \n",
    "\n",
    "We are reading the dataset file using the read_parquet() function from pandas. This function reads the file in the Parquet format and assigns it to data. Parquet is a columnar storage file format that is commonly used for storing and processing big data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "YB2Igb5UOLyT"
   },
   "outputs": [],
   "source": [
    "# Importing the file path using parquet function\n",
    "filepath = '/Users/harish/Desktop/Human Acivity Recognition/Data/Train_data.gzip'\n",
    "data = pd.read_parquet(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s look at the number of rows and columns of the dataset. As you can see, we have a large dataset of one lakh rows and 563 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "scy6wZJLOLyU",
    "outputId": "31dcdf91-7f3c-42e2-e7b5-39cfadee2a10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 563)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the few samples of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>date_time</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.229771</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>-0.063642</td>\n",
       "      <td>0.148432</td>\n",
       "      <td>-0.017294</td>\n",
       "      <td>-0.214122</td>\n",
       "      <td>0.109120</td>\n",
       "      <td>-0.140795</td>\n",
       "      <td>-0.060678</td>\n",
       "      <td>0.136123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669427</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>-0.503460</td>\n",
       "      <td>-0.695799</td>\n",
       "      <td>0.618240</td>\n",
       "      <td>-0.487791</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.012113</td>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>WALKING_DOWNSTAIRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.096259</td>\n",
       "      <td>-0.004479</td>\n",
       "      <td>-0.011539</td>\n",
       "      <td>-0.628955</td>\n",
       "      <td>-0.803592</td>\n",
       "      <td>-0.217212</td>\n",
       "      <td>-0.174894</td>\n",
       "      <td>-0.421507</td>\n",
       "      <td>-0.025912</td>\n",
       "      <td>-0.539172</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286686</td>\n",
       "      <td>-0.079703</td>\n",
       "      <td>0.052752</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>-0.014742</td>\n",
       "      <td>0.155335</td>\n",
       "      <td>-0.236586</td>\n",
       "      <td>-0.277595</td>\n",
       "      <td>2020-01-01 01:01:00</td>\n",
       "      <td>LAYING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034372</td>\n",
       "      <td>-0.043343</td>\n",
       "      <td>-0.311560</td>\n",
       "      <td>-0.075527</td>\n",
       "      <td>-0.063103</td>\n",
       "      <td>0.025375</td>\n",
       "      <td>-0.032692</td>\n",
       "      <td>-0.083888</td>\n",
       "      <td>0.127356</td>\n",
       "      <td>-0.021718</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136133</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>0.202458</td>\n",
       "      <td>0.084711</td>\n",
       "      <td>-0.297366</td>\n",
       "      <td>-0.540108</td>\n",
       "      <td>0.063798</td>\n",
       "      <td>0.131656</td>\n",
       "      <td>2020-01-01 01:02:00</td>\n",
       "      <td>WALKING_UPSTAIRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.024097</td>\n",
       "      <td>0.009133</td>\n",
       "      <td>-0.086416</td>\n",
       "      <td>0.071118</td>\n",
       "      <td>0.006441</td>\n",
       "      <td>-0.122816</td>\n",
       "      <td>-0.032050</td>\n",
       "      <td>0.024451</td>\n",
       "      <td>-0.164227</td>\n",
       "      <td>0.075734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206189</td>\n",
       "      <td>0.047049</td>\n",
       "      <td>0.292424</td>\n",
       "      <td>0.064996</td>\n",
       "      <td>0.100568</td>\n",
       "      <td>-0.682927</td>\n",
       "      <td>0.130937</td>\n",
       "      <td>0.021554</td>\n",
       "      <td>2020-01-01 01:03:00</td>\n",
       "      <td>WALKING_DOWNSTAIRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.225618</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.103685</td>\n",
       "      <td>-0.189633</td>\n",
       "      <td>-0.674050</td>\n",
       "      <td>-0.602043</td>\n",
       "      <td>-0.820340</td>\n",
       "      <td>-0.008993</td>\n",
       "      <td>-0.988655</td>\n",
       "      <td>-0.698891</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.843761</td>\n",
       "      <td>0.008899</td>\n",
       "      <td>-0.189814</td>\n",
       "      <td>-0.075739</td>\n",
       "      <td>-0.130241</td>\n",
       "      <td>-0.059553</td>\n",
       "      <td>-0.011284</td>\n",
       "      <td>-0.077751</td>\n",
       "      <td>2020-01-01 01:04:00</td>\n",
       "      <td>SITTING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n",
       "0           0.229771           0.006191          -0.063642          0.148432   \n",
       "1           0.096259          -0.004479          -0.011539         -0.628955   \n",
       "2           0.034372          -0.043343          -0.311560         -0.075527   \n",
       "3           0.024097           0.009133          -0.086416          0.071118   \n",
       "4           0.225618          -0.013047          -0.103685         -0.189633   \n",
       "\n",
       "   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n",
       "0         -0.017294         -0.214122          0.109120         -0.140795   \n",
       "1         -0.803592         -0.217212         -0.174894         -0.421507   \n",
       "2         -0.063103          0.025375         -0.032692         -0.083888   \n",
       "3          0.006441         -0.122816         -0.032050          0.024451   \n",
       "4         -0.674050         -0.602043         -0.820340         -0.008993   \n",
       "\n",
       "   tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  fBodyBodyGyroJerkMag-kurtosis()  \\\n",
       "0         -0.060678          0.136123  ...                        -0.669427   \n",
       "1         -0.025912         -0.539172  ...                        -0.286686   \n",
       "2          0.127356         -0.021718  ...                        -0.136133   \n",
       "3         -0.164227          0.075734  ...                        -0.206189   \n",
       "4         -0.988655         -0.698891  ...                        -0.843761   \n",
       "\n",
       "   angle(tBodyAccMean,gravity)  angle(tBodyAccJerkMean),gravityMean)  \\\n",
       "0                     0.001615                             -0.503460   \n",
       "1                    -0.079703                              0.052752   \n",
       "2                     0.005180                              0.202458   \n",
       "3                     0.047049                              0.292424   \n",
       "4                     0.008899                             -0.189814   \n",
       "\n",
       "   angle(tBodyGyroMean,gravityMean)  angle(tBodyGyroJerkMean,gravityMean)  \\\n",
       "0                         -0.695799                              0.618240   \n",
       "1                          0.000921                             -0.014742   \n",
       "2                          0.084711                             -0.297366   \n",
       "3                          0.064996                              0.100568   \n",
       "4                         -0.075739                             -0.130241   \n",
       "\n",
       "   angle(X,gravityMean)  angle(Y,gravityMean)  angle(Z,gravityMean)  \\\n",
       "0             -0.487791              0.006897              0.012113   \n",
       "1              0.155335             -0.236586             -0.277595   \n",
       "2             -0.540108              0.063798              0.131656   \n",
       "3             -0.682927              0.130937              0.021554   \n",
       "4             -0.059553             -0.011284             -0.077751   \n",
       "\n",
       "            date_time            Activity  \n",
       "0 2020-01-01 01:00:00  WALKING_DOWNSTAIRS  \n",
       "1 2020-01-01 01:01:00              LAYING  \n",
       "2 2020-01-01 01:02:00    WALKING_UPSTAIRS  \n",
       "3 2020-01-01 01:03:00  WALKING_DOWNSTAIRS  \n",
       "4 2020-01-01 01:04:00             SITTING  \n",
       "\n",
       "[5 rows x 563 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s extract the major sensor names out of the 563 column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "2f4LN25ThFcA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Activity',\n",
       " 'angle(X,gravityMean)',\n",
       " 'angle(Y,gravityMean)',\n",
       " 'angle(Z,gravityMean)',\n",
       " 'angle(tBodyAccJerkMean),gravityMean)',\n",
       " 'angle(tBodyAccMean,gravity)',\n",
       " 'angle(tBodyGyroJerkMean,gravityMean)',\n",
       " 'angle(tBodyGyroMean,gravityMean)',\n",
       " 'date_time',\n",
       " 'fBodyAcc',\n",
       " 'fBodyAccJerk',\n",
       " 'fBodyAccMag',\n",
       " 'fBodyBodyAccJerkMag',\n",
       " 'fBodyBodyGyroJerkMag',\n",
       " 'fBodyBodyGyroMag',\n",
       " 'fBodyGyro',\n",
       " 'tBodyAcc',\n",
       " 'tBodyAccJerk',\n",
       " 'tBodyAccJerkMag',\n",
       " 'tBodyAccMag',\n",
       " 'tBodyGyro',\n",
       " 'tBodyGyroJerk',\n",
       " 'tBodyGyroJerkMag',\n",
       " 'tBodyGyroMag',\n",
       " 'tGravityAcc',\n",
       " 'tGravityAccMag'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors = set()\n",
    "for col in data.columns:\n",
    "    sensors.add(col.split(\"-\")[0])\n",
    "sensors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can observe most of the features are related to acceleration, gyrometer readings and angle. \n",
    "Now, Let’s check if any class imbalance is present in the Activity column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dIsu_DF6OLyU",
    "outputId": "9e908b91-ce0b-4535-9018-2ad379c7ba63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LAYING                16762\n",
       "WALKING               16728\n",
       "WALKING_UPSTAIRS      16675\n",
       "STANDING              16645\n",
       "WALKING_DOWNSTAIRS    16627\n",
       "SITTING               16563\n",
       "Name: Activity, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Activity'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can infer that the labels in the activity columns are distributed almost fairly, indicating the absence of class imbalance.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let’s perform the label encoding on the 'Activity' column of the DataFrame using the LabelEncoder from scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "iWhMlctvOLyV"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data['Activity'] = le.fit_transform(data['Activity'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check the mapping of labels to the activity types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - ['LAYING']\n",
      "1 - ['SITTING']\n",
      "2 - ['STANDING']\n",
      "3 - ['WALKING']\n",
      "4 - ['WALKING_DOWNSTAIRS']\n",
      "5 - ['WALKING_UPSTAIRS']\n"
     ]
    }
   ],
   "source": [
    "for label_code,count in sorted((data['Activity'].value_counts()).items()):\n",
    "    label_name = le.inverse_transform([label_code])\n",
    "    print(f\"{(label_code)} - {label_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could observe that 0 maps to Laying, 1 map to Sitting, 2 maps to standing, 3 maps to walking, 4 maps to walking_downstairs, and 5 maps to walking_upstairs.  \n",
    "So, let’s now proceed to data preparation!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s now prepare a dataset for machine learning. Let’s separate the feature variable and target variable.\n",
    "Also let’s restrict our features to sensor reading by dropping the 'date_time' feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 561)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(['date_time','Activity'] , axis = 1)\n",
    "y = data['Activity']\n",
    "X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have 561 features in the dataset which may result in computational complexity, and potentially lead to overfitting. To avoid these challenges let's define a function “get_top_k_features” to extract the most relevant features. The function takes three arguments namely X, Y and k. Where\n",
    "\n",
    "* X is the Input feature,\n",
    "* Y is the Target variable, and\n",
    "* K is the number the features that we want\n",
    "\n",
    "We will be using a decision tree based model called “ExtraTreesClassifier” to get the most important features, since tree based models have a feature importance attribute. Next, the sort function sorts the features in descending order of importance. Finally, we are extracting the top k feature names and storing them in a list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_features(X, y, k):\n",
    "    clf = ExtraTreesClassifier(n_estimators=150)\n",
    "    clf = clf.fit(X, y)\n",
    "    feature_df = pd.DataFrame(data=(X.columns, clf.feature_importances_)).T.sort_values(by=1, ascending=False)\n",
    "    cols = feature_df.head(k)[0].values\n",
    "    return cols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s make a dataset with 10 features. Feel free to use a different number of features to improve your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_features = get_top_k_features(X, y, k=10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don’t worry if this process takes a little bit of time. Since, this is a large dataset building models and tuning models for this data will take some time. Now, let’s print the top 10 extracted features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_10_features: ['tGravityAcc-energy()-X' 'angle(X,gravityMean)' 'tGravityAcc-min()-X'\n",
      " 'tGravityAcc-mean()-X' 'tGravityAcc-max()-X' 'tGravityAcc-min()-Y'\n",
      " 'tGravityAcc-mean()-Y' 'tGravityAcc-max()-Y' 'angle(Y,gravityMean)'\n",
      " 'tBodyAcc-max()-X']\n"
     ]
    }
   ],
   "source": [
    "print('top_10_features:', top_10_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TLDuXT51OLyX"
   },
   "source": [
    "Lets Subset the original input features X based on the extracted, top 10 features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_10 = X[top_10_features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trimmed our dataset, let’s split the dataset into train and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "_5eisMMtOLyX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tGravityAcc-energy()-X</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>tGravityAcc-min()-X</th>\n",
       "      <th>tGravityAcc-mean()-X</th>\n",
       "      <th>tGravityAcc-max()-X</th>\n",
       "      <th>tGravityAcc-min()-Y</th>\n",
       "      <th>tGravityAcc-mean()-Y</th>\n",
       "      <th>tGravityAcc-max()-Y</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98980</th>\n",
       "      <td>-0.565443</td>\n",
       "      <td>0.242414</td>\n",
       "      <td>-0.101913</td>\n",
       "      <td>-0.200780</td>\n",
       "      <td>-0.009404</td>\n",
       "      <td>0.017509</td>\n",
       "      <td>0.206466</td>\n",
       "      <td>0.128182</td>\n",
       "      <td>-0.067901</td>\n",
       "      <td>-0.309997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69824</th>\n",
       "      <td>-0.675749</td>\n",
       "      <td>0.018377</td>\n",
       "      <td>-0.010389</td>\n",
       "      <td>-0.071852</td>\n",
       "      <td>-0.227970</td>\n",
       "      <td>0.559071</td>\n",
       "      <td>0.291151</td>\n",
       "      <td>0.431229</td>\n",
       "      <td>-0.424456</td>\n",
       "      <td>-0.417692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9928</th>\n",
       "      <td>0.483607</td>\n",
       "      <td>-0.133690</td>\n",
       "      <td>0.262396</td>\n",
       "      <td>0.412074</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>-0.207874</td>\n",
       "      <td>-0.077072</td>\n",
       "      <td>-0.051626</td>\n",
       "      <td>0.067471</td>\n",
       "      <td>-0.008146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75599</th>\n",
       "      <td>0.153450</td>\n",
       "      <td>-0.198148</td>\n",
       "      <td>0.245780</td>\n",
       "      <td>0.281915</td>\n",
       "      <td>0.504597</td>\n",
       "      <td>-0.006724</td>\n",
       "      <td>-0.148600</td>\n",
       "      <td>-0.192616</td>\n",
       "      <td>0.159822</td>\n",
       "      <td>0.004341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95621</th>\n",
       "      <td>0.101471</td>\n",
       "      <td>-0.235995</td>\n",
       "      <td>0.414753</td>\n",
       "      <td>0.201402</td>\n",
       "      <td>0.396144</td>\n",
       "      <td>-0.210965</td>\n",
       "      <td>-0.202314</td>\n",
       "      <td>-0.218439</td>\n",
       "      <td>0.137819</td>\n",
       "      <td>0.130354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tGravityAcc-energy()-X  angle(X,gravityMean)  tGravityAcc-min()-X  \\\n",
       "98980               -0.565443              0.242414            -0.101913   \n",
       "69824               -0.675749              0.018377            -0.010389   \n",
       "9928                 0.483607             -0.133690             0.262396   \n",
       "75599                0.153450             -0.198148             0.245780   \n",
       "95621                0.101471             -0.235995             0.414753   \n",
       "\n",
       "       tGravityAcc-mean()-X  tGravityAcc-max()-X  tGravityAcc-min()-Y  \\\n",
       "98980             -0.200780            -0.009404             0.017509   \n",
       "69824             -0.071852            -0.227970             0.559071   \n",
       "9928               0.412074             0.006954            -0.207874   \n",
       "75599              0.281915             0.504597            -0.006724   \n",
       "95621              0.201402             0.396144            -0.210965   \n",
       "\n",
       "       tGravityAcc-mean()-Y  tGravityAcc-max()-Y  angle(Y,gravityMean)  \\\n",
       "98980              0.206466             0.128182             -0.067901   \n",
       "69824              0.291151             0.431229             -0.424456   \n",
       "9928              -0.077072            -0.051626              0.067471   \n",
       "75599             -0.148600            -0.192616              0.159822   \n",
       "95621             -0.202314            -0.218439              0.137819   \n",
       "\n",
       "       tBodyAcc-max()-X  \n",
       "98980         -0.309997  \n",
       "69824         -0.417692  \n",
       "9928          -0.008146  \n",
       "75599          0.004341  \n",
       "95621          0.130354  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train1 , x_test1 , y_train1 , y_test1 = train_test_split(X_10, y, random_state=42, test_size=0.25)\n",
    "x_train1.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our dataset is ready. Let’s try to build a few models and compare their performance to select the best-performing model. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wx6QQIfFOLyY"
   },
   "source": [
    "## 4. Model Training\n",
    "\n",
    "Here we are going to use Logistic regression, decision tree and random Forest to build models and compare the results. Feel free to try other machine learning models as well. \n",
    "\n",
    "First, let’s import the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "yUyLP2H8XZqv"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Model training with top 10 features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To store and organise the results obtained from different model experiments for the top 10 features, let’s create an empty dictionary as model_result_10f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "4EYf32et-GXx"
   },
   "outputs": [],
   "source": [
    "model_result_10f = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start with a logistic regression model, evaluate its accuracy on both the training and testing sets, and then store the results in the dictionary, model_result_10f. We will also store helpful remarks for each model to keep a track of model experimentation. In this case we have added the remark as “Model with top 10 features without standard scaling. Maximum iterations = 1000.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wETq5fckOLyY",
    "outputId": "3b273a34-acf8-46d1-c3b5-09c71a9feab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy 72.2\n",
      "Test Accuracy 71.67\n"
     ]
    }
   ],
   "source": [
    "lr1 =  LogisticRegression(max_iter=1000)\n",
    "lr1.fit(x_train1, y_train1)\n",
    "train_accuracy = round(lr1.score(x_train1, y_train1)*100,2)\n",
    "test_accuracy = round(lr1.score(x_test1, y_test1)*100,2)\n",
    "print(\"Training Accuracy\", train_accuracy)\n",
    "print(\"Test Accuracy\", test_accuracy)\n",
    "model_result_10f['Logistic_Regression'] = {'Train_accuracy': train_accuracy,'Test_accuracy':test_accuracy,'Remark':'Model with top 10 features without standard scaling. Maximum iterations = 1000.'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the logistic regression model:\n",
    "The training accuracy is ___  percent and the test accuracy is ____. The logistic regression accuracy is quite low. \n",
    "\n",
    "Let’s do the same exercise for the decision tree classifier and store the results in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MBPnw_JqUwJ3",
    "outputId": "108c3ca0-4b6c-4684-dc13-4f151096c695"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy 100.0\n",
      "Test Accuracy 65.63\n"
     ]
    }
   ],
   "source": [
    "dt1 =  DecisionTreeClassifier(random_state=42)\n",
    "dt1.fit(x_train1, y_train1)\n",
    "train_accuracy = round(dt1.score(x_train1, y_train1)*100,2)\n",
    "test_accuracy = round(dt1.score(x_test1, y_test1)*100,2)\n",
    "print(\"Training Accuracy\", train_accuracy)\n",
    "print(\"Test Accuracy\", test_accuracy)\n",
    "model_result_10f['Decision_Tree'] = {'Train_accuracy': train_accuracy,'Test_accuracy':test_accuracy, \"Remark\":\"Model with top 10 features without standard scaling. Random_state 42.\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the DecisionTreeClassifier model:\n",
    "The training accuracy is ___ percent and the test accuracy is ___. \n",
    "This shows a very high level of overfitting, so we should try random forest. \n",
    "\n",
    "Just like the previous two models, here we are training a random forest classifier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MLVpq5k4VVNS",
    "outputId": "8808e07b-57c5-41e0-d75e-4002cd223632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy 100.0\n",
      "Test Accuracy 74.01\n"
     ]
    }
   ],
   "source": [
    "rfc1 =  RandomForestClassifier(n_estimators=100, random_state=60)\n",
    "rfc1.fit(x_train1, y_train1)\n",
    "train_accuracy = round(rfc1.score(x_train1, y_train1)*100,2)\n",
    "test_accuracy = round(rfc1.score(x_test1, y_test1)*100,2)\n",
    "print(\"Training Accuracy\", train_accuracy)\n",
    "print(\"Test Accuracy\", test_accuracy)\n",
    "model_result_10f['RandomForest'] = {'Train_accuracy': train_accuracy,'Test_accuracy':test_accuracy,\"Remark\":\"Model with top 10 features without standard scaling. 100 Decision trees. Random_state 42.\" }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the RandomForestClassifier model:\n",
    "The training accuracy is ____ percent and the test accuracy is ____. This is a minor improvement over the decision tree, but this performance is not as expected. So, let’s try to increase the performance by adding more features. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Model training with top 12 features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will increase the number of features to 12 and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_12_features: ['tGravityAcc-energy()-X' 'tGravityAcc-mean()-X' 'tGravityAcc-max()-X'\n",
      " 'tGravityAcc-min()-X' 'angle(X,gravityMean)' 'tGravityAcc-min()-Y'\n",
      " 'tGravityAcc-mean()-Y' 'tGravityAcc-max()-Y' 'angle(Y,gravityMean)'\n",
      " 'tBodyAcc-max()-X' 'tGravityAcc-energy()-Y' 'fBodyAcc-entropy()-X']\n"
     ]
    }
   ],
   "source": [
    "top_12_features = get_top_k_features(X, y, k=12)\n",
    "print(\"top_12_features:\", top_12_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Subset the original input features X_12 based on the extracted, top 12 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_12 = X[top_12_features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our desired features, let’s split the dataset into train and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tGravityAcc-energy()-X</th>\n",
       "      <th>tGravityAcc-mean()-X</th>\n",
       "      <th>tGravityAcc-max()-X</th>\n",
       "      <th>tGravityAcc-min()-X</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>tGravityAcc-min()-Y</th>\n",
       "      <th>tGravityAcc-mean()-Y</th>\n",
       "      <th>tGravityAcc-max()-Y</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>tGravityAcc-energy()-Y</th>\n",
       "      <th>fBodyAcc-entropy()-X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98980</th>\n",
       "      <td>-0.565443</td>\n",
       "      <td>-0.200780</td>\n",
       "      <td>-0.009404</td>\n",
       "      <td>-0.101913</td>\n",
       "      <td>0.242414</td>\n",
       "      <td>0.017509</td>\n",
       "      <td>0.206466</td>\n",
       "      <td>0.128182</td>\n",
       "      <td>-0.067901</td>\n",
       "      <td>-0.309997</td>\n",
       "      <td>-0.507090</td>\n",
       "      <td>-0.018885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69824</th>\n",
       "      <td>-0.675749</td>\n",
       "      <td>-0.071852</td>\n",
       "      <td>-0.227970</td>\n",
       "      <td>-0.010389</td>\n",
       "      <td>0.018377</td>\n",
       "      <td>0.559071</td>\n",
       "      <td>0.291151</td>\n",
       "      <td>0.431229</td>\n",
       "      <td>-0.424456</td>\n",
       "      <td>-0.417692</td>\n",
       "      <td>0.646694</td>\n",
       "      <td>-0.792774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9928</th>\n",
       "      <td>0.483607</td>\n",
       "      <td>0.412074</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>0.262396</td>\n",
       "      <td>-0.133690</td>\n",
       "      <td>-0.207874</td>\n",
       "      <td>-0.077072</td>\n",
       "      <td>-0.051626</td>\n",
       "      <td>0.067471</td>\n",
       "      <td>-0.008146</td>\n",
       "      <td>-0.256825</td>\n",
       "      <td>-0.166796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75599</th>\n",
       "      <td>0.153450</td>\n",
       "      <td>0.281915</td>\n",
       "      <td>0.504597</td>\n",
       "      <td>0.245780</td>\n",
       "      <td>-0.198148</td>\n",
       "      <td>-0.006724</td>\n",
       "      <td>-0.148600</td>\n",
       "      <td>-0.192616</td>\n",
       "      <td>0.159822</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>-0.198441</td>\n",
       "      <td>0.431915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95621</th>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.201402</td>\n",
       "      <td>0.396144</td>\n",
       "      <td>0.414753</td>\n",
       "      <td>-0.235995</td>\n",
       "      <td>-0.210965</td>\n",
       "      <td>-0.202314</td>\n",
       "      <td>-0.218439</td>\n",
       "      <td>0.137819</td>\n",
       "      <td>0.130354</td>\n",
       "      <td>-0.057358</td>\n",
       "      <td>0.669723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tGravityAcc-energy()-X  tGravityAcc-mean()-X  tGravityAcc-max()-X  \\\n",
       "98980               -0.565443             -0.200780            -0.009404   \n",
       "69824               -0.675749             -0.071852            -0.227970   \n",
       "9928                 0.483607              0.412074             0.006954   \n",
       "75599                0.153450              0.281915             0.504597   \n",
       "95621                0.101471              0.201402             0.396144   \n",
       "\n",
       "       tGravityAcc-min()-X  angle(X,gravityMean)  tGravityAcc-min()-Y  \\\n",
       "98980            -0.101913              0.242414             0.017509   \n",
       "69824            -0.010389              0.018377             0.559071   \n",
       "9928              0.262396             -0.133690            -0.207874   \n",
       "75599             0.245780             -0.198148            -0.006724   \n",
       "95621             0.414753             -0.235995            -0.210965   \n",
       "\n",
       "       tGravityAcc-mean()-Y  tGravityAcc-max()-Y  angle(Y,gravityMean)  \\\n",
       "98980              0.206466             0.128182             -0.067901   \n",
       "69824              0.291151             0.431229             -0.424456   \n",
       "9928              -0.077072            -0.051626              0.067471   \n",
       "75599             -0.148600            -0.192616              0.159822   \n",
       "95621             -0.202314            -0.218439              0.137819   \n",
       "\n",
       "       tBodyAcc-max()-X  tGravityAcc-energy()-Y  fBodyAcc-entropy()-X  \n",
       "98980         -0.309997               -0.507090             -0.018885  \n",
       "69824         -0.417692                0.646694             -0.792774  \n",
       "9928          -0.008146               -0.256825             -0.166796  \n",
       "75599          0.004341               -0.198441              0.431915  \n",
       "95621          0.130354               -0.057358              0.669723  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2 , x_test2 , y_train2 , y_test2 = train_test_split(X_12, y, random_state=42, test_size=0.25)\n",
    "x_train2.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To store and organise the results obtained from different model experiments for the top 12 features, let’s create an empty dictionary as model_result_12f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result_12f= {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, we have already observed that the random forest model gave better results for the k10 feature. We will only try random forest models for K12 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy 99.99\n",
      "Test Accuracy 80.43\n"
     ]
    }
   ],
   "source": [
    "rfc2 =  RandomForestClassifier(n_estimators=50)\n",
    "rfc2.fit(x_train2, y_train2)\n",
    "train_accuracy = round(rfc2.score(x_train2, y_train2)*100,2)\n",
    "test_accuracy = round(rfc2.score(x_test2, y_test2)*100,2)\n",
    "print(\"Training Accuracy\", train_accuracy)\n",
    "print(\"Test Accuracy\", test_accuracy)\n",
    "model_result_12f['RandomForest'] = {'Train_accuracy': train_accuracy,'Test_accuracy':test_accuracy,\"Remark\": \"Model with top 12 features without standard scaling and 50 Decision trees\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the K12 Random Forest Classifier model:\n",
    "\n",
    "The training accuracy is ___ percent and the test accuracy is ___. We could observe a significant jump in the model performance with the increased feature variables. Feel free to try a larger number of features to improve the model performance further. Let’s now compare all the computed models for K10 and K12 features.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "DJuYo7Z1-CVh"
   },
   "source": [
    "## 5. Model comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s tabulate and print the various model results obtained using top 10 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "0oJyjBa3-BLg",
    "outputId": "e4247a96-4584-4b80-cb99-f224d2d35511"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_accuracy</th>\n",
       "      <th>Test_accuracy</th>\n",
       "      <th>Remark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic_Regression</th>\n",
       "      <td>72.2</td>\n",
       "      <td>71.67</td>\n",
       "      <td>Model with top 10 features without standard sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision_Tree</th>\n",
       "      <td>100.0</td>\n",
       "      <td>65.63</td>\n",
       "      <td>Model with top 10 features without standard sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>100.0</td>\n",
       "      <td>74.01</td>\n",
       "      <td>Model with top 10 features without standard sc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Train_accuracy Test_accuracy  \\\n",
       "Logistic_Regression           72.2         71.67   \n",
       "Decision_Tree                100.0         65.63   \n",
       "RandomForest                 100.0         74.01   \n",
       "\n",
       "                                                                Remark  \n",
       "Logistic_Regression  Model with top 10 features without standard sc...  \n",
       "Decision_Tree        Model with top 10 features without standard sc...  \n",
       "RandomForest         Model with top 10 features without standard sc...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result_10f = pd.DataFrame(model_result_10f).T\n",
    "model_result_10f"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly let’s print the model results obtained for top 12 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Remark</th>\n",
       "      <th>Test_accuracy</th>\n",
       "      <th>Train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>Model with top 12 features without standard sc...</td>\n",
       "      <td>80.43</td>\n",
       "      <td>99.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Remark Test_accuracy  \\\n",
       "RandomForest  Model with top 12 features without standard sc...         80.43   \n",
       "\n",
       "             Train_accuracy  \n",
       "RandomForest          99.99  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result_12f = pd.DataFrame(model_result_12f).T\n",
    "model_result_12f"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table, it is evident that the RandomForest model with top 12 features has performed better than other models. It has the highest validation accuracy. But there is still scope for improvement. Let’s carry out hyperparameter tuning for this model to improve it further."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning for K12 Random forest model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use GridSearchCV to perform hyperparameter tuning. In the below code GridSearchCV searches for the best combination of n_estimators, and max_depth using 3-fold cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(n_estimators=50),\n",
       "             param_grid={&#x27;max_depth&#x27;: [15, 20], &#x27;n_estimators&#x27;: [50, 100, 150]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(n_estimators=50),\n",
       "             param_grid={&#x27;max_depth&#x27;: [15, 20], &#x27;n_estimators&#x27;: [50, 100, 150]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=50)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=50)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(n_estimators=50),\n",
       "             param_grid={'max_depth': [15, 20], 'n_estimators': [50, 100, 150]})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "            \"n_estimators\": [\n",
    "                50,\n",
    "                100,\n",
    "                150,\n",
    "            ],\n",
    "            \"max_depth\": [15, 20]\n",
    "        }\n",
    "CV_rfc = GridSearchCV(estimator=rfc2, param_grid=param_grid, cv=3)\n",
    "CV_rfc.fit(x_train2, y_train2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best Hyperparameters are: \n",
    "* max_depth = 20\n",
    "* n_estimator = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=20, n_estimators=150)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, n_estimators=150)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=20, n_estimators=150)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s check the performance of the random forest model after hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result_12f_tuned={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy 94.91\n",
      "Test Accuracy 80.94\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = round(CV_rfc.score(x_train2, y_train2)*100,2)\n",
    "test_accuracy = round(CV_rfc.score(x_test2, y_test2)*100,2)\n",
    "print(\"Training Accuracy\", train_accuracy)\n",
    "print(\"Test Accuracy\", test_accuracy)\n",
    "model_result_12f_tuned['Hyperparameter_tuned_RandomForest'] = {'Train_accuracy': train_accuracy,'Test_accuracy':test_accuracy,\"Remark\": \"Model with top 12 features without standard scaling and Hyperparameter tuned\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Remark</th>\n",
       "      <th>Test_accuracy</th>\n",
       "      <th>Train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hyperparameter_tuned_RandomForest</th>\n",
       "      <td>Model with top 12 features without standard sc...</td>\n",
       "      <td>80.94</td>\n",
       "      <td>94.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              Remark  \\\n",
       "Hyperparameter_tuned_RandomForest  Model with top 12 features without standard sc...   \n",
       "\n",
       "                                  Test_accuracy Train_accuracy  \n",
       "Hyperparameter_tuned_RandomForest         80.94          94.91  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result_12f_tuned = pd.DataFrame(model_result_12f_tuned).T\n",
    "model_result_12f_tuned"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training accuracy of the model is ____ and test accuracy is ____. We can conclude that the model is not overfitting and we could observe a small improvement in test accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model Results "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s store the model results in a new directory named “model_results”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('model_results/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s save the model result of top 10 and top 12 features of both hyper parameters tuned model and the non-tuned model in our model_results directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model_results/model_result_12f_tuned.joblib']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "## Let's save the 10 features of model results.\n",
    "joblib.dump(model_result_10f, \"./model_results/model_result_10f.joblib\")\n",
    "## Let's save the top 12 features of model results.\n",
    "joblib.dump(model_result_12f, \"./model_results/model_result_12f.joblib\")\n",
    "## Let's save the top 12 features of hyper parameter tuned model results.\n",
    "joblib.dump(model_result_12f_tuned, \"./model_results/model_result_12f_tuned.joblib\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can check that the new models are saved successfully for future reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gxd3LAXNOLya"
   },
   "source": [
    "## 6. Model registration\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's come to the most exciting part of this notebook which is model registration. In MLOps model registry is an important component as discussed in the level 0 architecture, it helps in the easy retrieval and reuse of the model in the future. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let’s create two directories or folders named \"model_registry\" and \"model_features” for saving models and the features used to train the models respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "wje5qYKM_TlK"
   },
   "outputs": [],
   "source": [
    "## Change Drive path to your Folder\n",
    "os.mkdir('model_registry/')\n",
    "os.mkdir('model_features/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Saving Models "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s save three models. The two best performing models which are random forest based and the logistic regression model for diversity. We will use the joblib library to accomplish the same. Make sure that you name your model in a manner that your future self as well as others are able to understand the details about the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model_features/encoder_weights.joblib']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(le, \"./model_features/encoder_weights.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model_registry/K12-tuned-random_forest.joblib']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## K10 logistic regression model \n",
    "joblib.dump(lr1, \"./model_registry/K10-Logistic Regression.joblib\")\n",
    "## K12 random forest model \n",
    "joblib.dump(rfc2, \"./model_registry/K12-random_forest.joblib\")\n",
    "## K12 hyper parameter tuned random forest model \n",
    "joblib.dump(CV_rfc, \"./model_registry/K12-tuned-random_forest.joblib\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s save the features of the model. We will define a variable name “K10_Feature” and \"K12_tuned_Feature\" to save the feature columns of K10 and K12 features, used for training the model. They are saved to the directory: model_features. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Saving feature names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model_features/K12_train_features.joblib']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K10_Feature = np.array(x_train1.columns)\n",
    "joblib.dump(K10_Feature, \"./model_features/K10_train_features.joblib\")\n",
    "K12_Feature = np.array(x_train2.columns)\n",
    "joblib.dump(K12_Feature, \"./model_features/K12_train_features.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tGravityAcc-energy()-X', 'tGravityAcc-mean()-X',\n",
       "       'tGravityAcc-max()-X', 'tGravityAcc-min()-X',\n",
       "       'angle(X,gravityMean)', 'tGravityAcc-min()-Y',\n",
       "       'tGravityAcc-mean()-Y', 'tGravityAcc-max()-Y',\n",
       "       'angle(Y,gravityMean)', 'tBodyAcc-max()-X',\n",
       "       'tGravityAcc-energy()-Y', 'fBodyAcc-entropy()-X'], dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K12_Feature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Saving datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model_features/K12_train_dataset.joblib']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K10_dataset = np.array(x_train1)\n",
    "joblib.dump(K10_dataset, \"./model_features/K10_train_dataset.joblib\")\n",
    "K12_dataset = np.array(x_train2)\n",
    "joblib.dump(K12_dataset, \"./model_features/K12_train_dataset.joblib\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have successfully saved both model registry and model features. Now that you have saved your models you can use this to make predictions on new data any time in the future."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zXPQNg-2_e2Y"
   },
   "source": [
    "## 9. Model Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets load some new data to make predictions. For evaluating the new data performance we would be using the stored models and features. \n",
    "Don’t forget to update the file path of the new data, as we did earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 562)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load new data set \n",
    "new_data = pd.read_csv('/Users/harish/Desktop/Human Acivity Recognition/Data/new_data.csv')\n",
    "new_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new data contains 610 rows and 562 columns. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would need to do similar pre-processing on new data as we did on the train dataset. Let’s load the feature names to trim the dataset to 12 features and let’s also load the best performing model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "2NR-_bknBp-9"
   },
   "outputs": [],
   "source": [
    "## Load Features and model weight\n",
    "train_features = joblib.load(\"./model_features/K12_train_features.joblib\")\n",
    "\n",
    "model = joblib.load(\"./model_registry/K12-tuned-random_forest.joblib\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s trim the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "vjBigajfArp5"
   },
   "outputs": [],
   "source": [
    "new_data_features = new_data[train_features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we encounter issues in a new dataset that we did not encounter in the training dataset, like missing values. To ensure that the data is in the appropriate format for making predictions let's fill the missing values using the fillna() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hq/5r8lcknd643fb4ch7cgk8bp80000gn/T/ipykernel_61167/3780058617.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data_features.fillna(0,inplace = True)\n"
     ]
    }
   ],
   "source": [
    "new_data_features.fillna(0,inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that the new dataset is ready, let's carry out the prediction for the model. The trained model is used to predict the labels for the new data, and new_data_features using the predict() function. In the code below the predicted labels are assigned to the variable y_prediction. The predicted labels are then transformed back to the original activity labels using the inverse_transform() method of the LabelEncoder (le) and stored in y_prediction_label. Finally, the prediction labels are added as a new column named \"Prediction_label\" to the DataFrame, new_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "fvlbPro9_1E7"
   },
   "outputs": [],
   "source": [
    "y_prediction = model.predict(new_data_features)\n",
    "y_prediction_label = le.inverse_transform(y_prediction)\n",
    "new_data['Prediction_label'] = y_prediction_label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s have a look at the first few rows of the data frame. As you can see, the actual activity and the predicted activities are matching for the visible rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "2PdRdawoCmTp",
    "outputId": "574b153d-3b77-4c58-cdde-901261b8d2e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Prediction_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.710304</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "      <td>STANDING</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.861499</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "      <td>STANDING</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.760104</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "      <td>STANDING</td>\n",
       "      <td>SITTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.482845</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "      <td>STANDING</td>\n",
       "      <td>SITTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.699205</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>STANDING</td>\n",
       "      <td>SITTING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n",
       "0           0.288585          -0.020294          -0.132905         -0.995279   \n",
       "1           0.278419          -0.016411          -0.123520         -0.998245   \n",
       "2           0.279653          -0.019467          -0.113462         -0.995380   \n",
       "3           0.279174          -0.026201          -0.123283         -0.996091   \n",
       "4           0.276629          -0.016570          -0.115362         -0.998139   \n",
       "\n",
       "   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n",
       "0         -0.983111         -0.913526         -0.995112         -0.983185   \n",
       "1         -0.975300         -0.960322         -0.998807         -0.974914   \n",
       "2         -0.967187         -0.978944         -0.996520         -0.963668   \n",
       "3         -0.983403         -0.990675         -0.997099         -0.982750   \n",
       "4         -0.980817         -0.990482         -0.998321         -0.979672   \n",
       "\n",
       "   tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  fBodyBodyGyroJerkMag-kurtosis()  \\\n",
       "0         -0.923527         -0.934724  ...                        -0.710304   \n",
       "1         -0.957686         -0.943068  ...                        -0.861499   \n",
       "2         -0.977469         -0.938692  ...                        -0.760104   \n",
       "3         -0.989302         -0.938692  ...                        -0.482845   \n",
       "4         -0.990441         -0.942469  ...                        -0.699205   \n",
       "\n",
       "   angle(tBodyAccMean,gravity)  angle(tBodyAccJerkMean),gravityMean)  \\\n",
       "0                    -0.112754                              0.030400   \n",
       "1                     0.053477                             -0.007435   \n",
       "2                    -0.118559                              0.177899   \n",
       "3                    -0.036788                             -0.012892   \n",
       "4                     0.123320                              0.122542   \n",
       "\n",
       "   angle(tBodyGyroMean,gravityMean)  angle(tBodyGyroJerkMean,gravityMean)  \\\n",
       "0                         -0.464761                             -0.018446   \n",
       "1                         -0.732626                              0.703511   \n",
       "2                          0.100699                              0.808529   \n",
       "3                          0.640011                             -0.485366   \n",
       "4                          0.693578                             -0.615971   \n",
       "\n",
       "   angle(X,gravityMean)  angle(Y,gravityMean)  angle(Z,gravityMean)  Activity  \\\n",
       "0             -0.841247              0.179941             -0.058627  STANDING   \n",
       "1             -0.844788              0.180289             -0.054317  STANDING   \n",
       "2             -0.848933              0.180637             -0.049118  STANDING   \n",
       "3             -0.848649              0.181935             -0.047663  STANDING   \n",
       "4             -0.847865              0.185151             -0.043892  STANDING   \n",
       "\n",
       "   Prediction_label  \n",
       "0          STANDING  \n",
       "1          STANDING  \n",
       "2           SITTING  \n",
       "3           SITTING  \n",
       "4           SITTING  \n",
       "\n",
       "[5 rows x 563 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the performance of the model on the new dataset. \n",
    "\n",
    "We are assigning the “Activity” column from the new data to the “y_test” variable and the “Prediction_label” column from the test data to the “y_pred” variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = new_data['Activity'].astype(str)\n",
    "y_pred = new_data['Prediction_label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      0.99      1.00       112\n",
      "           SITTING       0.91      0.91      0.91        99\n",
      "          STANDING       0.91      0.93      0.92       112\n",
      "           WALKING       0.78      0.82      0.80       120\n",
      "WALKING_DOWNSTAIRS       0.94      0.99      0.96        69\n",
      "  WALKING_UPSTAIRS       0.77      0.68      0.72        98\n",
      "               nan       0.00      0.00      0.00         0\n",
      "\n",
      "          accuracy                           0.88       610\n",
      "         macro avg       0.76      0.76      0.76       610\n",
      "      weighted avg       0.88      0.88      0.88       610\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harish/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/harish/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/harish/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the evaluation report we can observe that the model has resulted in pretty high accuracy, precision, recall and f1-Score. This indicates that our model is performing quite well. The model is working particularly well for some activities like laying, sitting and standing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9LwA85fW_aiw"
   },
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
